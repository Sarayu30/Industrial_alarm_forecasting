


---

````markdown
# Optimizing Industrial Maintenance: Forecasting Alarm Behaviors with Machine Learning and Explainable AI

This repository contains Jupyter Notebook files focused on implementing data analysis, machine learning, and time series modeling. The project uses statistical tools, machine learning models, and explainable AI techniques to extract insights and provide transparent predictions.

---

## **Overview**

The repository includes the following key files:
- **`fds-project_final.ipynb`**: Implements core functionalities of the project, including data preprocessing, statistical computations, machine learning, and interactive visualizations.
- **`fds-timeseries_final.ipynb`**: Focuses on time series modeling, forecasting, and explainable AI for temporal data.

---

## **Objectives**

The main goals of this project are:
1. **Data Analysis**: Perform exploratory data analysis to identify patterns and insights.
2. **Time Series Modeling**: Implement models for forecasting and trend analysis.
3. **Explainable AI**: Use interpretable models to provide transparency in predictions.
4. **Result Visualization**: Present data and outcomes through clear and interactive visualizations.

---

## **Features**

### **`fds-project_final.ipynb`**
- Comprehensive data preprocessing and cleaning.
- Statistical computations to derive meaningful insights.
- Implementation of machine learning models:
  - Linear Regression
  - Random Forest
  - Gradient Boosting (XGBoost) and many more
- Application of explainable AI models:
  - **LIME**: Local Interpretable Model-Agnostic Explanations.
  - **SHAP**: SHapley Additive exPlanations.
- Interactive visualizations for better understanding of data and model outcomes.

### **`fds-timeseries_final.ipynb`**
- Dataset preparation for time series analysis.
- Time series models for forecasting:
  - ARIMA (AutoRegressive Integrated Moving Average)
  - SARIMA (Seasonal ARIMA)
  - Prophet Model
- Explainable AI for time series:
  - SHAP for model interpretability.
- Visualizations of temporal trends, seasonality, and forecasting results.

---

## **Requirements**

Ensure the following dependencies are installed in your environment:

- **Python**: Version 3.8 or above
- **Libraries**:
  - `pandas`
  - `numpy`
  - `matplotlib`
  - `seaborn`
  - `statsmodels`
  - `scikit-learn`
  - `xgboost`
  - `shap`
  - `lime`

---

## **Installation**

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/your-repo-link
````

2. **Install Dependencies**:

   ```bash
   pip install -r requirements.txt
   ```

---

## **Usage**

### Running the Notebooks

1. Launch Jupyter Notebook:

   ```bash
   jupyter notebook
   ```
2. Open and execute the notebooks in the following order:

   * **`fds-project_final.ipynb`**: For data analysis and machine learning.
   * **`fds-timeseries_final.ipynb`**: For time series modeling and forecasting.

---

## **Customization**

* Replace datasets within the notebooks to analyze your specific data.
* Modify parameters of machine learning and time series models to suit your use case.

---

## **Results**

### Visualizations

* **Line Charts**: To visualize trends over time.
* **Box Plots**: For distribution analysis.
* **LIME and SHAP Charts**: To explain model predictions.

### Model Performance Comparison

| Model               | Accuracy | Precision | Recall | F1-Score |
| ------------------- | -------- | --------- | ------ | -------- |
| XGBoost             | 98.91%   | 0.99      | 0.99   | 0.99     |
| Random Forest       | 97.82%   | 0.98      | 0.98   | 0.98     |
| Decision Tree       | 98.02%   | 0.98      | 0.98   | 0.98     |
| AdaBoost            | 44.85%   | 0.56      | 0.45   | 0.40     |
| Gradient Boosting   | 98.50%   | 0.99      | 0.98   | 0.99     |
| Naive Bayes         | 88.50%   | 0.89      | 0.89   | 0.89     |
| KNN                 | 98.52%   | 0.99      | 0.99   | 0.99     |
| SVM                 | 95.31%   | 0.95      | 0.95   | 0.95     |
| Logistic Regression | 87.54%   | 0.87      | 0.88   | 0.87     |

> üîç **Insight**: Among all models, **XGBoost**, **KNN**, and **Gradient Boosting** performed the best across all metrics. AdaBoost underperformed and may not be suitable for this dataset.

---

## **Contributing**

We welcome contributions to this project! Follow these steps:

1. Fork the repository.
2. Create a feature branch:

   ```bash
   git checkout -b feature-name
   ```
3. Commit your changes:

   ```bash
   git commit -m 'Add feature name'
   ```
4. Push to your branch:

   ```bash
   git push origin feature-name
   ```
5. Create a pull request.

---

Feel free to reach out with questions or suggestions. Happy coding! üòä
Made with ‚ù§Ô∏è by **Sarayu Krishna**

```

---

Let me know if you'd like a downloadable `.md` file or help pushing this to GitHub!
```
